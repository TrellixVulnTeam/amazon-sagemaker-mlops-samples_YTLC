{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeting Direct Marketing with Random Forest at Local\n",
    "_**Supervised Learning with Random Forest: A Binary Prediction Problem With Unbalanced Classes**_\n",
    "\n",
    "This notebook works well with the `Python 3 (Data Science)` kernel on SageMaker Studio.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Preperation](#Preparation)\n",
    "1. [Data](#Data)\n",
    "    1. [Exploration](#Exploration)\n",
    "    1. [Transformation](#Transformation)\n",
    "1. [Training](#Training)\n",
    "1. [Hosting](#Hosting)\n",
    "1. [Evaluation](#Evaluation)\n",
    "1. [Exentsions](#Extensions)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "In this workshop, you will learn how to use Amazon SageMaker Managed Notebook environment - <b>SageMaker Studio</b> to build, train and deploy a machine learning (ML) model using SKLearn framework.   \n",
    "\n",
    "In this exercise, you have been asked to to develop a machine learning model to predict whether a customer will enroll for a certificate of deposit (CD), after the customer has been contacted through mail, email, phone, etc.  The model will be trained on the marketing dataset that contains information on customer demographics, responses to marketing events, and environmental factors. Because resources and a customer's attention is limited, the goal is to only target the subset of prospects who are likely to engage with a specific offer.  \n",
    "\n",
    "The data has been labeled for your convenience and a column in the dataset identifies whether the customer is enrolled for a product offered by the bank. A version of this dataset is publicly available  from the ML repository curated by the University of California, Irvine (https://archive.ics.uci.edu/ml/datasets/bank+marketing). This tutorial implements a supervised machine learning model, since the data is labeled. (Unsupervised learning occurs when the datasets are not labeled.)\n",
    "\n",
    "The steps include:\n",
    "\n",
    "* Downloading training data into Amazon SageMaker\n",
    "* Investigating and transforming the data so that it can be fed to Amazon SageMaker algorithms\n",
    "* Fitting a model using Random Forest Classifier\n",
    "* Evaluating the effectiveness of the model\n",
    "* Setting the model up to make on-going predictions\n",
    "\n",
    "## Feature Engineering\n",
    "In this part of the tutorial, you will learn about the highlighted part of machine learning process:\n",
    "![png](./image/ML-pipeline.JPG)\n",
    "\n",
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "In this step you will use your Amazon SageMaker Studio notebook to preprocess the data that you need to train your machine learning model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute each cell by pressing <b> Shift+Enter </b> in each of the cells. While the code runs, an * appears between the square brackets as pictured in the first screenshot to the right. After a few seconds, the code execution will complete, the * will be replaced with the number 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "import boto3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure pandas version is set to 1.2.4 or later. If it is not the case, restart the kernel before going further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Downloading data\n",
    "Download the [direct marketing dataset](https://sagemaker-sample-data-us-west-2.s3-us-west-2.amazonaws.com/autopilot/direct_marketing/bank-additional.zip) from the sample data s3 bucket by running the \n",
    "\n",
    "\\[Moro et al., 2014\\] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 05\n",
    "# restore the shared variables\n",
    "%store -r bucket\n",
    "%store -r prefix\n",
    "%store -r data_folder\n",
    "%store -r data_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, you will load the dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 06\n",
    "data = pd.read_csv(data_file_path)\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)         # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "7. Let's start exploring the data.  First, let's understand how the features are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 07\n",
    "# Frequency tables for each categorical feature\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    display(pd.crosstab(index=data[column], columns='% observations', normalize='columns'))\n",
    "\n",
    "# Histograms for each numeric features\n",
    "display(data.describe())\n",
    "%matplotlib inline\n",
    "hist = data.hist(bins=30, sharey=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "\n",
    "* Almost 90% of the values for our target variable `y` are \"no\", so most customers did not subscribe to a term deposit.\n",
    "* Many of the predictive features take on values of `unknown`.  Some are more common than others.  We should think carefully as to what causes a value of \"unknown\" (are these customers non-representative in some way?) and how we that should be handled.\n",
    "  * Even if `unknown` is included as it's own distinct category, what does it mean given that, in reality, those observations likely fall within one of the other categories of that feature?\n",
    "* Many of the predictive features have categories with very few observations in them.  If we find a small category to be highly predictive of our target outcome, do we have enough evidence to make a generalization about that?\n",
    "* Contact timing is particularly skewed.  Almost a third in May and less than 1% in December.  What does this mean for predicting our target variable next December?\n",
    "* There are no missing values in our numeric features.  Or missing values have already been imputed.\n",
    "  * `pdays` takes a value near 1000 for almost all customers.  Likely a placeholder value signifying no previous contact.\n",
    "* Several numeric features have a very long tail.  Do we need to handle these few observations with extremely large values differently?\n",
    "* Several numeric features (particularly the macroeconomic ones) occur in distinct buckets.  Should these be treated as categorical?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at how our features relate to the target that we are attempting to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 08\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    if column != 'y':\n",
    "        display(pd.crosstab(index=data[column], columns=data['y'], normalize='columns'))\n",
    "\n",
    "for column in data.select_dtypes(exclude=['object']).columns:\n",
    "    print(column)\n",
    "    hist = data[[column, 'y']].hist(by='y', bins=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "\n",
    "* Customers who are-- blue-collar\", \"married\", \"unknown\" default status, contacted by \"telephone\", and/or in \"may\" are a substantially lower portion of \"yes\" than \"no\" for subscribing.\n",
    "* Distributions for numeric variables are different across \"yes\" and \"no\" subscribing groups, but the relationships may not be straightforward or obvious.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Now let's look at how our features relate to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 09 -- using a correlation matrix and scatter matrix understand how features are related to one another\n",
    "display(data.corr())\n",
    "pd.plotting.scatter_matrix(data, figsize=(12, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "* Features vary widely in their relationship with one another.  Some with highly negative correlation, others with highly positive correlation.\n",
    "* Relationships between features is non-linear and discrete in many cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "\n",
    "Cleaning up data is part of nearly every machine learning project.  It arguably presents the biggest risk if done incorrectly and is one of the more subjective aspects in the process.  Several common techniques include:\n",
    "\n",
    "* <b>Handling missing values:</b> Some machine learning algorithms are capable of handling missing values, but most would rather not.  Options include:\n",
    " * <b>Removing observations with missing values:</b> This works well if only a very small fraction of observations have incomplete information.\n",
    " * <b>Removing features with missing values</b>: This works well if there are a small number of features which have a large number of missing values.\n",
    " * <b>Imputing missing values</b>: Entire [books](https://www.amazon.com/Flexible-Imputation-Missing-Interdisciplinary-Statistics/dp/1439868247) have been written on this topic, but common choices are replacing the missing value with the mode or mean of that column's non-missing values.\n",
    "* <b>Converting categorical to numeric</b>: The most common method is one hot encoding, which for each feature maps every distinct value of that column to its own feature which takes a value of 1 when the categorical feature is equal to that value, and 0 otherwise.\n",
    "* <b>Oddly distributed data</b>: Although for non-linear models like Gradient Boosted Trees, this has very limited implications, parametric models like regression can produce wildly inaccurate estimates when fed highly skewed data.  In some cases, simply taking the natural log of the features is sufficient to produce more normally distributed data.  In others, bucketing values into discrete ranges is helpful.  These buckets can then be treated as categorical variables and included in the model when one hot encoded.\n",
    "* Handling more complicated data types: Mainpulating images, text, or data at varying grains is left for other notebook templates.\n",
    "\n",
    "Luckily, some of these aspects have already been handled for us, and the algorithm we are showcasing tends to do well at handling sparse or oddly distributed data.  Therefore, let's keep pre-processing simple.\n",
    "\n",
    "To summarise, we need to A) address some weird values, B) convert the categorical to numeric valriables and C) Remove unnecessary data:\n",
    "\n",
    "* Many records have the value of \"999\" for pdays. It is very likely to be a 'magic' number to represent that no contact was made before. Considering that, we will create a new column called \"no_previous_contact\", then grant it value of \"1\" when pdays is 999 and \"0\" otherwise.\n",
    "* In the job column, there are more than one categories for people who don't work e.g., \"student\", \"retired\", and \"unemployed\". It is very likely the decision to enroll or not to a term deposit depends a lot on whether the customer is working or not. A such, we generate a new column to show whether the customer is working based on job column.\n",
    "* We will remove the economic features and duration from our data as they would need to be forecasted with high precision to be used as features during inference time.\n",
    "* We convert categorical variables to numeric using one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator variable to capture when pdays takes a value of 999\n",
    "data['no_previous_contact'] = np.where(data['pdays'] == 999, 1, 0)                                 \n",
    "\n",
    "# Indicator for individuals not actively employed\n",
    "data['not_working'] = np.where(np.in1d(data['job'], ['student', 'retired', 'unemployed']), 1, 0)   \n",
    "\n",
    "# remove unnecessary data\n",
    "data = data.drop(\n",
    "    ['duration', \n",
    "     'emp.var.rate', \n",
    "     'cons.price.idx', \n",
    "     'cons.conf.idx', \n",
    "     'euribor3m', \n",
    "     'nr.employed'\n",
    "    ], \n",
    "    axis=1)\n",
    "\n",
    "# Convert categorical variables to sets of indicators\n",
    "model_data = pd.get_dummies(data)                    \n",
    "\n",
    "# Replace \"y_no\" and \"y_yes\" with a single label column, and bring it to the front:\n",
    "model_data = pd.concat([model_data['y_yes'], model_data.drop(['y_no', 'y_yes'], axis=1)], axis=1)\n",
    "\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data\n",
    "When building a model whose primary goal is to predict a target value on new data, it is important to understand <b> overfitting</b>.  Supervised learning models are designed to minimize error between their predictions of the target value and actuals, in the data they are given.  This last part is key, as frequently in their quest for greater accuracy, machine learning models bias themselves toward picking up on minor idiosyncrasies within the data they are shown.  These idiosyncrasies then don't repeat themselves in subsequent data, meaning those predictions can actually be made less accurate, at the expense of more accurate predictions in the training phase.\n",
    "The most common way of preventing this is to build models with the concept that a model shouldn't only be judged on its fit to the data it was trained on, but also on <b>\"new\"</b> data.  There are several different ways of operationalizing this, holdout validation, cross-validation, leave-one-out validation, etc.  For our purposes, we'll simply randomly split the data into 3 uneven groups.  \n",
    "\n",
    "Use Numpy to split data into 3 groups. The model will be trained on 70% of data, it will then be evaluated on 20% of data to give us an estimate of the accuracy we hope to have on \"new\" data, and 10% will be held back as a final testing dataset which will be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12 - split our data into 3 channels: train, test,validation sets\n",
    "train_data, validation_data = np.split(\n",
    "    model_data.sample(frac=1, random_state=1729), \n",
    "    [int(0.8 * len(model_data))])   # Randomly sort the data then split out first 70%, second 20%, and last 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13\n",
    "X_train, y_train = train_data.iloc[:, 1:], train_data.iloc[:, 0]\n",
    "\n",
    "X_val, y_val = validation_data.iloc[:, 1:], validation_data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hyper_parameters = {\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_depth\": [12, 13],\n",
    "    \"max_features\": [13, 14],\n",
    "    \"n_estimators\": [100, 150]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(model, hyper_parameters, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation\n",
    "There are many ways to compare the performance of a machine learning model, but let's start by simply comparing actual values to predicted values.  In particular, we evaluate the model using a <b> confusion matrix </b>.   In this case, we're simply predicting whether the customer subscribed to a term deposit (`1`) or not (`0`).\n",
    "\n",
    "First we'll need to determine how we pass data into and receive data from our endpoint.  Our data is currently stored as NumPy arrays in memory of our notebook instance.  To send it in an HTTP POST request, we'll serialize it as a CSV string and then decode the resulting CSV.\n",
    "\n",
    "*Note: For inference with CSV format, SageMaker XGBoost requires that the data does NOT include the target variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(y_test, y_pred):\n",
    "    print(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted']))\n",
    "    print('====================')\n",
    "    print(\"Accuracy : \", \"{:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"Precision : \", \"{:.2f}\".format(precision_score(y_test, y_pred)))\n",
    "    print(\"Recall : \",\"{:.2f}\".format(recall_score(y_test, y_pred)))\n",
    "    print(\"F1 :\", \"{:.2f}\".format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_val)\n",
    "evaluate_performance(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "In this workshop we have walked through the process of building, training, tuning and evaluating the model with Random Forest Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
